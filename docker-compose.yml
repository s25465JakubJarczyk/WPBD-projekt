version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: business_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - backend

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - backend

  debezium:
    image: debezium/connect:2.4
    container_name: debezium
    depends_on:
      - kafka
      - postgres
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: debezium_config
      OFFSET_STORAGE_TOPIC: debezium_offsets
      STATUS_STORAGE_TOPIC: debezium_status
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    networks:
      - backend

  python-loader:
    build: .
    container_name: python-loader
    depends_on:
      - postgres
    command: python load_data.py
    networks:
      - backend

  minio:
    image: minio/minio:RELEASE.2024-04-18T19-09-19Z
    container_name: minio
    ports:
      - "9100:9000"  # MinIO API
      - "9101:9001"  # MinIO Web UI
    volumes:
      - minio-data:/data
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    command: server --console-address ":9001" /data
    networks:
      - backend

  spark:
    image: bitnami/spark:3.5.0
    container_name: spark
    depends_on:
      - kafka
      - minio
    ports:
      - "7077:7077"
      - "4040:4040"
    volumes:
      - .:/app
    working_dir: /app
    command:
      [
        "/opt/bitnami/spark/bin/spark-submit",
        "--packages",
        "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.0.0,org.apache.hadoop:hadoop-aws:3.3.4",
        "--conf", "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension",
        "--conf", "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog",
        "--conf", "spark.hadoop.fs.s3a.access.key=minioadmin",
        "--conf", "spark.hadoop.fs.s3a.secret.key=minioadmin123",
        "--conf", "spark.hadoop.fs.s3a.endpoint=http://minio:9000/",
        "--conf", "spark.hadoop.fs.s3a.path.style.access=true",
        "spark_streaming.py"
      ]
    environment:
      SPARK_MODE: master
      SPARK_UI_PORT: "4040"
    networks:
      - backend

volumes:
  postgres_data:
  minio-data:

networks:
  backend:
